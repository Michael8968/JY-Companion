"""Emotional companion agent â€” empathetic dialogue with crisis-aware safety."""

import structlog

from app.agents.base_agent import AgentContext, AgentResponse, BaseAgent
from app.models.conversation import AgentType
from app.services.crisis_alert import CRISIS_RESPONSES, check_crisis_keywords
from app.services.emotion_detector import EmotionDetector
from app.services.intervention_strategies import get_strategies_for_emotion
from app.services.llm_client import LLMClient
from app.services.prompt_manager import PromptManager

logger = structlog.get_logger()

# Empathetic system prompt extension
EMPATHY_SYSTEM_PROMPT = (
    "\n\n--- æƒ…æ„Ÿé™ªä¼´ä¸“é¡¹æŒ‡å¼• ---\n"
    "1. å§‹ç»ˆä»¥æŽ¥çº³ã€ä¸è¯„åˆ¤çš„æ€åº¦å›žåº”å­¦ç”Ÿçš„æ„Ÿå—ã€‚\n"
    "2. ä½¿ç”¨ã€Œæˆ‘å¬åˆ°ä½ è¯´â€¦â€¦ã€ã€Œä½ çš„æ„Ÿå—æ˜¯å¯ä»¥ç†è§£çš„ã€ç­‰å…±æƒ…è¡¨è¾¾ã€‚\n"
    "3. å¤šç”¨å¼€æ”¾å¼é—®é¢˜å¼•å¯¼å­¦ç”Ÿè¡¨è¾¾ï¼Œå¦‚ã€Œä½ æ„¿æ„å¤šè¯´è¯´å—ï¼Ÿã€ã€‚\n"
    "4. é€‚æ—¶æŽ¨èå…·ä½“çš„å¿ƒç†è°ƒèŠ‚æŠ€å·§ï¼ˆå‘¼å¸ç»ƒä¹ ã€æ­£å¿µç»ƒä¹ ç­‰ï¼‰ã€‚\n"
    "5. ä¸è¦ç»™å‡ºç®€å•çš„å»ºè®®æˆ–è¯´æ•™ï¼Œè€Œæ˜¯é™ªä¼´å­¦ç”ŸæŽ¢ç´¢è‡ªå·±çš„æ„Ÿå—ã€‚\n"
    "6. å¦‚æžœå­¦ç”ŸæŒç»­ä½Žè½ï¼Œæ¸©æŸ”åœ°å»ºè®®å¯»æ±‚å­¦æ ¡å¿ƒç†å’¨è¯¢å¸ˆçš„å¸®åŠ©ã€‚\n"
    "--- æŒ‡å¼•ç»“æŸ ---"
)


class EmotionalAgent(BaseAgent):
    """Emotional companion agent with empathetic dialogue and crisis detection."""

    def __init__(self) -> None:
        self._llm = LLMClient()
        self._prompt_manager = PromptManager()
        self._detector = EmotionDetector()

    async def process(self, context: AgentContext) -> AgentResponse:
        user_input = context.user_input

        # Step 1: Crisis keyword pre-check (synchronous, <100ms)
        crisis_result = check_crisis_keywords(user_input)
        if crisis_result.is_crisis:
            logger.warning(
                "emotional_agent.crisis_detected",
                user_id=context.user_id,
                level=crisis_result.alert_level,
                keywords=crisis_result.matched_keywords,
            )
            safe_response = CRISIS_RESPONSES.get(
                crisis_result.alert_level,
                CRISIS_RESPONSES[list(CRISIS_RESPONSES.keys())[0]],
            )
            return AgentResponse(
                content=safe_response,
                agent_type=AgentType.EMOTIONAL,
                emotion_label="crisis",
                metadata={
                    "crisis": True,
                    "alert_level": crisis_result.alert_level,
                    "matched_keywords": crisis_result.matched_keywords,
                },
            )

        # Step 2: Detect emotion from text
        emotion_result = self._detector.detect_from_text(user_input)

        # Step 3: Build context-enriched prompt
        enriched_input = user_input
        if context.rag_context:
            enriched_input = f"{context.rag_context}\n\nç”¨æˆ·æ¶ˆæ¯: {user_input}"

        # Add detected emotion context for the LLM
        emotion_hint = (
            f"\n\n[ç³»ç»Ÿæç¤ºï¼šæ£€æµ‹åˆ°å­¦ç”Ÿå½“å‰æƒ…ç»ªä¸ºã€Œ{emotion_result.label.value}ã€ï¼Œ"
            f"æƒ…æ„Ÿæ•ˆä»·={emotion_result.valence:.2f}ï¼Œå”¤é†’åº¦={emotion_result.arousal:.2f}ï¼Œ"
            f"ç½®ä¿¡åº¦={emotion_result.confidence:.2f}ã€‚è¯·æ®æ­¤è°ƒæ•´å›žåº”çš„è¯­æ°”å’Œæ–¹å‘ã€‚]"
        )

        messages = self._prompt_manager.build_messages(
            AgentType.EMOTIONAL,
            context.history,
            enriched_input + emotion_hint,
            persona=context.persona,
        )
        # Inject empathy guidelines into system prompt
        messages[0]["content"] += EMPATHY_SYSTEM_PROMPT

        # Step 4: Get intervention suggestions for negative emotions
        intervention_note = ""
        if emotion_result.valence < -0.3:
            strategies = get_strategies_for_emotion(emotion_result.label, max_results=3)
            if strategies:
                suggestions = "ã€".join(s.name for s in strategies)
                intervention_note = (
                    f"\n\nðŸ’š ä½ å¯ä»¥è¯•è¯•è¿™äº›æ”¾æ¾æŠ€å·§ï¼š{suggestions}ã€‚"
                    "éœ€è¦æˆ‘è¯¦ç»†ä»‹ç»å…¶ä¸­ä¸€ä¸ªå—ï¼Ÿ"
                )

        # Step 5: Generate empathetic response via LLM
        try:
            result = await self._llm.generate(messages)
            content = result["content"]
            if intervention_note:
                content += intervention_note
        except Exception:
            await logger.aexception("emotional_agent.llm_failed")
            content = (
                "æˆ‘æ„Ÿå—åˆ°ä½ çŽ°åœ¨å¯èƒ½ä¸å¤ªèˆ’æœã€‚è™½ç„¶æˆ‘æš‚æ—¶æ— æ³•å®Œæ•´å›žåº”ï¼Œ"
                "ä½†è¯·è®°ä½ä½ çš„æ„Ÿå—æ˜¯é‡è¦çš„ã€‚å¦‚æžœéœ€è¦å¸®åŠ©ï¼Œå¯ä»¥æ‰¾å­¦æ ¡å¿ƒç†å’¨è¯¢å¸ˆèŠèŠã€‚"
            )

        return AgentResponse(
            content=content,
            agent_type=AgentType.EMOTIONAL,
            emotion_label=emotion_result.label.value,
            emotion_score=emotion_result.confidence,
            metadata={
                "valence": emotion_result.valence,
                "arousal": emotion_result.arousal,
                "scores": emotion_result.scores,
            },
        )

    def get_capabilities(self) -> list[str]:
        return [
            "empathetic_dialogue",
            "emotion_detection",
            "crisis_detection",
            "intervention_recommendation",
            "gratitude_journaling",
        ]

    def get_agent_type(self) -> AgentType:
        return AgentType.EMOTIONAL
